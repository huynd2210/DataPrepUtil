import pprint
import textwrap
from typing import Optional

import pandas as pd

from core.distillation import distillKnowledge, distillUnverifiedEntries, redistillEntries
from core.evaluation import evaluateModel
from core.utils import merge_csv_files, load_json_to_class


def prettyPrintCSV(path: str, chosenColumns: Optional[list[str]] = None):
    df = pd.read_csv(path, on_bad_lines='warn')
    if chosenColumns is not None:
        df = df[chosenColumns]
    textWrapWidth = 160
    batch_size = 10  # Number of rows to display at a time

    # Iterate in batches
    for start_idx in range(0, len(df), batch_size):
        end_idx = start_idx + batch_size
        batch = df.iloc[start_idx:end_idx]

        for index, row in batch.iterrows():
            if row["isVerified"] == 0 or row["isVerified"] is None:

                print(f" Question: {row['question']}" , end="\n\n")
                print(textwrap.fill("reasoning: " + row["reasoning"], textWrapWidth), end="\n\n")
                if type(row["verification_solution"]) == float:
                    print("0" * 20)
                    print(row["verification_solution"])
                print(textwrap.fill("gold_solution: " + row["gold_solution"], textWrapWidth), end="\n\n")
                print(textwrap.fill("verification_solution: " + str(row["verification_solution"]), textWrapWidth), end="\n\n")
                print(textwrap.fill("isVerified: " + str(row["isVerified"]), textWrapWidth), end="\n\n")
                # print(textwrap.fill("schema: " + row["schema"], textWrapWidth), end="\n\n")
                print("-" * 20)
                print("\n")

        # Pause before displaying the next batch
        if end_idx < len(df):  # Avoid asking for input after the last batch
            input("Press Enter to view the next set of rows...")
    # pprint.pprint(df)


def analyseEvaluation(evaluationResultDf: pd.DataFrame):
    counter = 0
    for index, row in evaluationResultDf.iterrows():
        if row["isCorrect"]:
            counter += 1

    print("Accuracy: " + str(counter / len(evaluationResultDf)))

def distillWrapper(model_name: str, student_model_name: str, dataset="spider", split="train", batchRange: Optional[tuple[int, int]] = None):
    data = distillKnowledge(model_name, student_model_name, dataset=dataset, split=split, batchRange=batchRange)
    outputName = f"{model_name.replace(':', '-')}_distilled_data_{dataset}_{split}_{batchRange[0]}_{batchRange[1]}.csv"
    print(f"Output saved to {outputName}")
    data.to_csv(outputName)

def redistillWrapper(
        file_path: str,
        model_name: str,
):
    pd = distillUnverifiedEntries(file_path, model_name)
    outputName = file_path.replace(".csv", "_redistilled.csv")
    print(f"Output saved to {outputName}")
    pd.to_csv(outputName)



if __name__ == '__main__':
    entriesIndex = [5012, 5021, 5022, 5027, 5039, 5053, 5079, 5084, 5092, 5094, 5130, 5155,5231, 5232, 5252, 5266, 5287,
                    5294, 5310, 5353, 5365, 5368, 5371, 5372, 5400, 5414, 5415, 5421, 5431, 5433, 5437, 5440, 5442, 5447,
                    5455, 5469, 5524, 5542, 5551, 5560, 5569, 5571, 5602, 5621, 5623, 5624, 5625, 5646, 5656, 5667, 5722,
                    5727, 5749, 5758, 5767, 5791, 5800, 5805, 5823, 5824, 5840, 5918, 5919, 5920, 5930, 5932, 5961, 6026,
                    6068, 6070, 6109, 6111, 6157, 6158, 6177, 6190, 6197, 6203, 6204, 6301, 6317, 6390, 6413, 6415, 6416,
                    6418, 6456, 6487, 6509, 6511, 6512, 6558, 6570, 6610, 6649, 6651, 6692, 6699, 6749, 6757, 6759, 6779,
                    6792, 6821, 6827, 6864, 6867, 6870, 6895, 6939, 6964, 6994, 
                    ]
    redistillEntries(
        inputFilePath="datasets/distilled_spider_train/spider-train-distilled.csv",
        outputFilePath="datasets/distilled_spider_train/spider-train-redistilled.csv",
        model_name="gpt-4o",
        entriesIndex=entriesIndex
    )


    # prettyPrintCSV(
    #     "datasets/distilled_spider_train/gpt-4o-mini-distilled-spider-train_redistilled.csv",
    #     ["question", "gold_solution", "reasoning", "verification_solution", "isVerified", "schema"]
    # )

    # model_name = "gpt-4o-mini"
    # # student_model_name = "gpt-4o-mini"
    # redistillWrapper(
    #     "datasets/distilled_spider_train/gpt-4o-mini-distilled-spider-train.csv",
    #     "gpt-4o",
    #     "gpt-4o-mini",
    # )


    # student_model_name = "qwen2.5-coder:7b-instruct"

    # split = "test"
    # # batchRange = (4001, 7000)
    # # distillWrapper(model_name, student_model_name, datasetName, split, batchRange)
    #
    # # model_name = "llama3.1:8b-instruct-q4_0"
    # model_name = "qwen2.5-coder:7b-instruct"
    # #
    # # model_name = "qwen2.5-coder:0.5b-instruct-fp16"
    # datasetName = "spider"
    # result = evaluateModel(model_name, datasetName, split=split)
    # analyseEvaluation(result)
    # print("----RESULT----")
    # print(result)
    # outputName = f"{model_name.replace(':', '-')}_{datasetName}_result.csv"
    # print(f"Output saved to {outputName}")
    # result.to_csv(outputName)

    # data = distillKnowledge(model_name, dataset=datasetName, batchRange=batchRange)
    # outputName = f"{model_name.replace(':', '-')}_distilled_data_{datasetName}_{split}_{batchRange[0]}_{batchRange[1]}.csv"
    # print(f"Output saved to {outputName}")
    # data.to_csv(outputName)

    # df = pd.read_csv("qwen2.5-coder-14b-instruct-q4_K_M_distilled_data.csv")
    # print(df["reasoning"].iloc[0])

    # generatedSQL = """
    # SELECT COUNT(*)
    # FROM head AS h
    # WHERE h.age > 56;
    # """
    # gold = """SELECT COUNT(*) FROM head WHERE age > 56;"""
    # path = "spider_data/database/department_management/department_management.sqlite"
    # sample = SQLEvaluationEntry(path, generatedSQL, gold, "question")
    # evaluateSQLGenerationEntry(sample)
